# -*- coding: utf-8 -*-
"""LM_Final_Project_BrainTumor_Tabular_Colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17h0o3XXGpaOJXgvmzEzm0K66Q5kemgO3

# Final Project — Medical Tabular Classification (Brain Tumor + Breast Cancer)

**Author:** Leonardo Machado  
**Course:** Stanford Continuing Studies — Applied ML with Python  
**Date:** 2025-08-29

1. Project Title, Problem Statement, Objectives & Goals  
2. Methodology & Block Diagram (pipeline)  
3. Datasets (Brain Tumor)  
4. Data Visualization & Feature Engineering notes  
5. 8 Algorithms:
  5.1) LogReg,
  5.2) SVM-linear
  5.3) SVM-RBF
  5.4) kNN
  5.5) DecisionTree
  5.6) RandomForest
  5.6) GradientBoosting
  5.7) MLP
6. Experiments, Metrics, Comparison Tables/Graphs  
7. Optimization & Test Results
8. Standards/Constraints, Bias/Ethics, Limitations, Conclusion & Future Work

## 0) Setup
Reproducibility, imports, and utility functions.
"""

import numpy as np, pandas as pd, matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score, recall_score,
                             precision_score, confusion_matrix, classification_report,
                             RocCurveDisplay, ConfusionMatrixDisplay)
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import tensorflow as tf
from tensorflow.keras import models, layers
from sklearn.datasets import load_breast_cancer
import os

#Garantee reproducibility
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)
tf.random.set_seed(RANDOM_STATE)

#Setting matplotlib styling
plt.rcParams['figure.figsize'] = (6,4)
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.6
plt.rcParams['grid.linestyle'] = '--'

"""## 1) Project framing
**Problem Statement:** Tumor detection from image-derived tabular features to support triage.

**Objectives & Goals:**
- Train **8 algorithms** (mix of classical ML + shallow DL).
- Prioritize **Recall (tumor class)** and **ROC-AUC**; include interpretability (coefficients/feature importances).

**Methodology / Pipeline:** Preprocess data → Split (test/validation data) → Pipeline(Scaler→Model) → CV + GridSearch → Test → Plots → Analysis.

## 2) Load Datasets
We use your Brain Tumor CSV and a comparator dataset (Breast Cancer Wisconsin) from scikit-learn.

**Instructions for Colab:**
1. Upload `Brain Tumor.csv` to Colab root (`/content`).
2. If not uploaded, run the upload cell below.
"""

from google.colab import files
#If the file is not already uploaded, upload the dataset
if not os.path.exists('/content/Brain Tumor.csv'):
    print('Upload Brain Tumor.csv...')
    #Upload file
    uploaded = files.upload()

#Define dataset path
bt_path = '/content/Brain Tumor.csv'
#Read dataset into bt variable
bt = pd.read_csv(bt_path)

# Features: drop non-feature column 'Image' and keep 'Class' as target if present
X_bt = bt.drop(columns=[c for c in ['Image','Class'] if c in bt.columns])
y_bt = bt['Class'].astype(int)

# Comparator dataset
bc = load_breast_cancer()
X_bc = pd.DataFrame(bc.data, columns=bc.feature_names)
y_bc = pd.Series(bc.target, name='Class')

print('Brain Tumor shape:', X_bt.shape, ' target n:', y_bt.shape)
print('Breast Cancer shape:', X_bc.shape, ' target n:', y_bc.shape)

# Class balance quick look
print('\nBrain Tumor class counts:\n', y_bt.value_counts())
print('\nBreast Cancer class counts:\n', y_bc.value_counts())

"""## 3) Train/Test Split"""

from sklearn.model_selection import train_test_split


def prep_split(X, y, test_size=0.2, seed=RANDOM_STATE):
    # Stratify preserves label ratios in train vs test
    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=seed)

X_bt_tr, X_bt_te, y_bt_tr, y_bt_te = prep_split(X_bt, y_bt)
X_bc_tr, X_bc_te, y_bc_tr, y_bc_te = prep_split(X_bc, y_bc)

print('BT train/test:', X_bt_tr.shape, X_bt_te.shape)
print('BC train/test:', X_bc_tr.shape, X_bc_te.shape)

"""## 4) Models & Hyperparameter Grids (8 total)
We’ll use GridSearchCV (StratifiedKFold=5) and ROC-AUC as the performance metric.
"""

from sklearn.model_selection import StratifiedKFold, GridSearchCV

#A dictionary models_grids with 7 Machine Learning Methods
#Pipeline chain pre-processing and the model together
#StandardScaler to standardize features -> especially important for distance-based algorithms

models_grids = {
    'LogReg': (
        Pipeline([('scaler', StandardScaler()),
                  ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE))]),
        {'clf__C':[0.1,1,10]}
    ),
    'SVM-Linear': (
        Pipeline([('scaler', StandardScaler()),
                  ('clf', SVC(kernel='linear', probability=True, class_weight='balanced', random_state=RANDOM_STATE))]),
        {'clf__C':[0.1,1,10]}
    ),
    'SVM-RBF': (
        Pipeline([('scaler', StandardScaler()),
                  ('clf', SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=RANDOM_STATE))]),
        {'clf__C':[0.5,1,5], 'clf__gamma':['scale','auto']}
    ),
    'kNN': (
        Pipeline([('scaler', StandardScaler()),
                  ('clf', KNeighborsClassifier())]),
        {'clf__n_neighbors':[3,5,7,9]}
    ),
    'DecisionTree': (
        DecisionTreeClassifier(max_depth=None, class_weight='balanced', random_state=RANDOM_STATE),
        {'max_depth':[None,3,5,7], 'min_samples_leaf':[1,3,5]}
    ),
    'RandomForest': (
        RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),
        {'max_depth':[None,5,10], 'min_samples_leaf':[1,3,5]}
    ),
    'GradientBoosting': (
        GradientBoostingClassifier(random_state=RANDOM_STATE),
        {'learning_rate':[0.05,0.1], 'n_estimators':[150,250], 'max_depth':[2,3]}
    ),
    #Multilayer Perceptron
    'MLP': (
        Pipeline([('scaler', StandardScaler()), ('clf', None)]),
        {}
    )
}

def cv_fit_best(name, estimator, param_grid, Xtr, ytr):
    # Training set is split into 5 folds.
    # StratifiedKFold ensures each fold has the same class balance as the whole dataset.
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
    # Define a dictionary of cadidate values for each hyperparameter
    # Tries every combination
    # Utilizes ROC_AUC as performance metric. Measures how well the model ranks positive cases above negative cases.
    # Refit=true retrains a fresh model on the entire training set using the best hyperparameters
    gs = GridSearchCV(estimator, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, refit=True)
    gs.fit(Xtr, ytr)
    return gs.best_estimator_, gs.best_score_, gs.best_params_

def evaluate_on_test(model, Xte, yte):
    y_pred = model.predict(Xte)
    try:
        y_proba = model.predict_proba(Xte)[:,1]
    except Exception:
        dec = model.decision_function(Xte)
        y_proba = (dec - dec.min()) / (dec.max() - dec.min() + 1e-9)
    metrics = {
        'accuracy': accuracy_score(yte, y_pred),
        'precision': precision_score(yte, y_pred, zero_division=0),
        'recall': recall_score(yte, y_pred, zero_division=0),
        'f1': f1_score(yte, y_pred, zero_division=0),
        'roc_auc': roc_auc_score(yte, y_proba),
    }
    return metrics, y_pred, y_proba

"""## 5) Keras MLP (shallow DL)
Feedforward network to complete the 8 algorithms.
"""

# Default number of neurons in the hidden layers = 64
# Dropout rate to reduce overfitting = 10%
def build_mlp(input_dim, hidden=64, dropout=0.1):
    m = models.Sequential([
        layers.Input(shape=(input_dim,)),
        layers.Dense(hidden, activation='relu'),
        layers.Dropout(dropout),
        layers.Dense(1, activation='sigmoid')
    ])
    #Sigmoid activation function so output is between 0 and 1
    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return m

def run_mlp(Xtr, ytr, Xte, yte, epochs=40, batch=32):
    # Build MLP
    mlp = build_mlp(Xtr.shape[1])
    # Standardize trainning and test data
    scaler = StandardScaler().fit(Xtr)
    Xtr_s = scaler.transform(Xtr)
    Xte_s = scaler.transform(Xte)
    # If model does not improve for 5 epochs, model stops early
    es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')
    hist = mlp.fit(Xtr_s, ytr, validation_split=0.2, epochs=epochs, batch_size=batch, verbose=0, callbacks=[es])
    y_proba = mlp.predict(Xte_s, verbose=0).ravel()
    y_pred = (y_proba >= 0.5).astype(int)
    metrics = {
        'accuracy': accuracy_score(yte, y_pred),
        'precision': precision_score(yte, y_pred, zero_division=0),
        'recall': recall_score(yte, y_pred, zero_division=0),
        'f1': f1_score(yte, y_pred, zero_division=0),
        'roc_auc': roc_auc_score(yte, y_proba),
    }
    return mlp, scaler, hist.history, metrics, y_pred, y_proba

"""## 6) Run Experiment Suite on Both Datasets
Trains/tunes classical models with CV, runs MLP, collects results, and prints comparison tables.
"""

def run_suite(dataset_name, Xtr, ytr, Xte, yte):
    rows = []
    fitted = {}
    for name, (est, grid) in models_grids.items():
        if name != 'MLP':
            best_model, cv_auc, best_params = cv_fit_best(name, est, grid, Xtr, ytr)
            test_metrics, y_pred, y_proba = evaluate_on_test(best_model, Xte, yte)
            rows.append({'Dataset': dataset_name, 'Model': name, 'CV_ROC_AUC': cv_auc, **test_metrics, 'BestParams': best_params})
            fitted[name] = {'model': best_model, 'y_pred': y_pred, 'y_proba': y_proba}
        else:
            mlp, scaler, history, test_metrics, y_pred, y_proba = run_mlp(Xtr, ytr, Xte, yte)
            rows.append({'Dataset': dataset_name, 'Model': 'MLP', 'CV_ROC_AUC': np.nan, **test_metrics, 'BestParams': {'hidden':64,'dropout':0.1}})
            fitted['MLP'] = {'model': mlp, 'scaler': scaler, 'history': history, 'y_pred': y_pred, 'y_proba': y_proba}
    df = pd.DataFrame(rows).sort_values(['Dataset','roc_auc'], ascending=[True,False]).reset_index(drop=True)
    return df, fitted

bt_results, bt_fitted = run_suite('BrainTumor', X_bt_tr, y_bt_tr, X_bt_te, y_bt_te)
bc_results, bc_fitted = run_suite('BreastCancer', X_bc_tr, y_bc_tr, X_bc_te, y_bc_te)

print('Brain Tumor results:')
display(bt_results)
print('\nBreast Cancer results:')
display(bc_results)

"""## 7) Plots — Best Model per Dataset
Confusion Matrix and ROC Curve using the recorded predictions.
"""

def best_by_auc(results_df):
    return results_df.loc[results_df['roc_auc'].idxmax(), 'Model']

def plot_test_curves(dataset_name, results_df, fitted, Xte, yte):
    best_model_name = best_by_auc(results_df)
    y_pred = fitted[best_model_name]['y_pred']
    y_proba = fitted[best_model_name]['y_proba']

    # Confusion Matrix
    disp = ConfusionMatrixDisplay.from_predictions(yte, y_pred)
    plt.title(f"{dataset_name} — Confusion Matrix ({best_model_name})")
    plt.show()

    # ROC Curve
    RocCurveDisplay.from_predictions(yte, y_proba)
    plt.title(f"{dataset_name} — ROC Curve ({best_model_name})")
    plt.show()

plot_test_curves('BrainTumor', bt_results, bt_fitted, X_bt_te, y_bt_te)
#plot_test_curves('BreastCancer', bc_results, bc_fitted, X_bc_te, y_bc_te)

"""## 8) Notes on Standards, Bias/Ethics, Limitations, and Future Work
- **Standards & Constraints:** Reproducibility (seeds), leakage avoidance (pipelines), CV splits (stratified), compute-light.
- **Bias/Ethics/Fairness:** No demographics → subgroup fairness can’t be assessed; risk of false negatives → clinical caution; model is assistive, not diagnostic.
- **Limitations:** Tabular surrogates of images; no external validation; unknown acquisition bias.
- **Future Work:** External validation, threshold tuning for recall, model calibration, raw-image CNNs to replace hand-crafted features.
"""